apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    adapter.model.aibrix.ai/enabled: "true"
    model.aibrix.ai/name: llama2-7b
    model.aibrix.ai/port: "8000"
  name: mock-llama2-7b
  namespace: default
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      adapter.model.aibrix.ai/enabled: "true"
      app: mock-llama2-7b
      model.aibrix.ai/name: llama2-7b
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 100%
    type: RollingUpdate
  template:
    metadata:
      labels:
        adapter.model.aibrix.ai/enabled: "true"
        app: mock-llama2-7b
        model.aibrix.ai/name: llama2-7b
    spec:
      containers:
      - command:
        - python3
        - app.py
        # - --replica_config_device
        # - a40
        # - --api_key
        # - sk-kFJ12nKsFVfVmGpj3QzX65s4RbN2xJqWzPYCjYu7wT3BlbLi
        env:
        - name: DEPLOYMENT_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app']
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        image: aibrix/vllm-mock:nightly
        imagePullPolicy: IfNotPresent
        name: llm-engine
        ports:
        - containerPort: 8000
          protocol: TCP
        resources:
          limits:
            cpu: "2"
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      - command:
        - aibrix_runtime
        - --port
        - "8080"
        env:
        - name: INFERENCE_ENGINE
          value: vllm
        - name: INFERENCE_ENGINE_ENDPOINT
          value: http://localhost:8000
        image: aibrix/runtime:nightly
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 3
          periodSeconds: 2
          successThreshold: 1
          timeoutSeconds: 1
        name: aibrix-runtime
        ports:
        - containerPort: 8080
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /ready
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: mocked-app-sa
      serviceAccountName: mocked-app-sa
      terminationGracePeriodSeconds: 5