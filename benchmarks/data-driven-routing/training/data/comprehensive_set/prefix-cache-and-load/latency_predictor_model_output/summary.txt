LLM Latency Prediction Model Summary
========================================

Total samples: 3242
Training samples: 2593
Test samples: 649
Target variables: avg_tpot, ttft

Model Parameters:
----------------------------------------
n_estimators: 100
max_depth: 5
learning_rate: 0.1

Cross-Validation Results:
----------------------------------------

avg_tpot:
  RMSE: 2.2495 ± 0.2026
  Stability: Very stable (CV variation ratio: 0.09)

ttft:
  RMSE: 270.0826 ± 24.2033
  Stability: Very stable (CV variation ratio: 0.09)

Test Results:
----------------------------------------

avg_tpot:
  mse: 3.7270
  rmse: 1.9305
  mae: 1.3159
  r2: 0.9944
  mape: 3.1175
  Quality: Excellent - Model explains >90% of variance
  No signs of overfitting detected

ttft:
  mse: 51134.7969
  rmse: 226.1300
  mae: 142.1567
  r2: 0.9465
  mape: 32.7657
  Quality: Excellent - Model explains >90% of variance
  No signs of overfitting detected

Top Features:
----------------------------------------

avg_tpot:
  last_second_avg_tpot_ms: 0.4927
  output_tokens: 0.2033
  decode_tokens: 0.1373
  running_requests: 0.0423
  gpu_kv_cache: 0.0273

ttft:
  waiting_requests: 0.6141
  output_tokens: 0.0946
  last_second_avg_tpot_ms: 0.0680
  decode_tokens: 0.0553
  running_requests: 0.0246
