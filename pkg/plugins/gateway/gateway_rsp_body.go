/*
Copyright 2024 The Aibrix Team.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package gateway

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/openai/openai-go"
	"github.com/openai/openai-go/packages/ssestream"
	"k8s.io/klog/v2"

	configPb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
	extProcPb "github.com/envoyproxy/go-control-plane/envoy/service/ext_proc/v3"
	envoyTypePb "github.com/envoyproxy/go-control-plane/envoy/type/v3"
	"github.com/vllm-project/aibrix/pkg/types"
	"github.com/vllm-project/aibrix/pkg/utils"
)

func (s *Server) handleStreamingResponse(requestID string, responseBody []byte) (openai.CompletionUsage, bool, *extProcPb.ProcessingResponse) {
	lines := strings.Split(string(responseBody), "\n")
	existingUsageRaw, _ := s.streamingUsageCache.LoadOrStore(requestID, openai.CompletionUsage{})
	existingUsage := existingUsageRaw.(openai.CompletionUsage)
	timingObj, exists := utils.RequestTimings.Load(requestID)
	if !exists {
		return existingUsage, false, nil
	}
	timing := timingObj.(*RequestTiming)
	prefill_token_count := int(timing.prefillTokenCount)
	currentTime := time.Now()
	routerCtxObj, exists := s.routingContexts.Load(requestID)
	if !exists {
		return existingUsage, false, nil
	}
	routerCtx := routerCtxObj.(*types.RoutingContext)
	selectedPodIP := routerCtx.TargetAddressWithoutPort()
	podIPWithoutPort := routerCtx.TargetAddressWithoutPort()
	t := &http.Response{
		Body: io.NopCloser(bytes.NewReader(responseBody)),
	}
	streaming := ssestream.NewStream[openai.ChatCompletionChunk](ssestream.NewDecoder(t), nil)
	for streaming.Next() {
		evt := streaming.Current()
		if len(evt.Choices) > 0 && evt.Choices[0].Delta.Content != "" {
			// First token response
			if timing.firstTokenTime.IsZero() {
				timing.IsPrefill = false
				timing.decodeTokenCount = 1 // one token is generated by stream mode for the first response
				timing.firstTokenTime = currentTime
				timing.lastTokenTime = currentTime
				ttftMs := currentTime.Sub(timing.startTime).Milliseconds()
				if ttftMs > 0 {
					klog.V(5).Infof("First token received, requestID: %s, podIP: %s, ttft_ms: %d, AddPodMetric", requestID, selectedPodIP, ttftMs)
					utils.MetricsTracker.AddPodMetric(selectedPodIP, utils.PodMetric{
						RequestID:       requestID,
						Timestamp:       currentTime,
						TTFT:            ttftMs,
						TPOT:            0,
						PrefillTokenNum: int64(prefill_token_count),
						DecodeTokenNum:  1,
					})
				} else {
					klog.Errorf("Negative ttft_ms: %d, requestID: %s, podIP: %s", ttftMs, requestID, selectedPodIP)
				}
				klog.V(5).InfoS("First token received", "requestID", requestID, "ttft_ms", ttftMs)

				ret := utils.DecrementNumPrefillTokensForPod(podIPWithoutPort, prefill_token_count)
				klog.V(5).Infof("DecrementNumPrefillTokensForPod(%s) by %d, %d", podIPWithoutPort, prefill_token_count, ret)

				ret = utils.IncrementNumDecodeTokensForPod(podIPWithoutPort, prefill_token_count+1)
				klog.V(5).Infof("IncrementNumDecodeTokensForPod(%s) by %d, %d", podIPWithoutPort, prefill_token_count+1, ret)

				ret = utils.IncrementNumDecodeTokensForRequest(requestID, prefill_token_count+1)
				klog.V(5).Infof("IncrementNumDecodeTokensForRequest(%s) by %d, %d", requestID, prefill_token_count+1, ret)
			} else { // Decode token response
				if timing.firstDecodeTokenTime.IsZero() {
					// First decode token
					timing.firstDecodeTokenTime = currentTime
					klog.V(5).Infof("First decode token received, requestID,%s, timing.prefillTokenCount.%d", requestID, timing.prefillTokenCount)
				}
				timing.decodeTokenCount++
				ret := utils.IncrementNumDecodeTokensForRequest(requestID, 1)
				klog.V(5).Infof("IncrementNumDecodeTokensForRequest(%s) by 1, %d", requestID, ret)

				ret = utils.IncrementNumDecodeTokensForPod(podIPWithoutPort, 1)
				klog.V(5).Infof("IncrementNumDecodeTokensForPod(%s) by 1, %d", podIPWithoutPort, ret)

				timeSincePrevToken := currentTime.Sub(timing.lastTokenTime).Milliseconds()
				if timeSincePrevToken > 0 {
					klog.V(5).Infof("Decoded token received, requestID: %s, podIP: %s, tpot_ms: %d, AddPodMetric", requestID, selectedPodIP, timeSincePrevToken)
					utils.MetricsTracker.AddPodMetric(selectedPodIP, utils.PodMetric{
						RequestID:       requestID,
						Timestamp:       currentTime,
						TTFT:            0,
						TPOT:            timeSincePrevToken,
						PrefillTokenNum: 0,
						DecodeTokenNum:  timing.decodeTokenCount,
					})
				}
			}
			klog.V(5).Infof("Token received, requestID: %s, timing.decodeTokenCount: %d, timing.prefillTokenCount: %d", requestID, timing.decodeTokenCount, timing.prefillTokenCount)
			timing.lastTokenTime = currentTime
			timing.totalTokenCount++
		}
	}

	if err := streaming.Err(); err != nil {
		klog.ErrorS(err, "error processing streaming response", "requestID", requestID)

		complete := true
		errorResponse := generateErrorResponse(
			envoyTypePb.StatusCode_InternalServerError,
			[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
				Key: HeaderErrorStreaming, RawValue: []byte("true"),
			}}},
			err.Error())

		return existingUsage, complete, errorResponse
	}

	for i := len(lines) - 1; i >= 0; i-- {
		line := strings.TrimSpace(lines[i])

		if !strings.HasPrefix(line, "data:") || line == "data: [DONE]" {
			continue
		}

		cleanLine := strings.TrimPrefix(line, "data: ")

		var chunk map[string]interface{}
		if err := json.Unmarshal([]byte(cleanLine), &chunk); err != nil {
			continue
		}

		if usageMap, ok := chunk["usage"].(map[string]interface{}); ok {
			promptTokens := int64(usageMap["prompt_tokens"].(float64))
			completionTokens := int64(usageMap["completion_tokens"].(float64))
			totalTokens := int64(usageMap["total_tokens"].(float64))

			if promptTokens > 0 || completionTokens > 0 || totalTokens > 0 {
				newUsage := openai.CompletionUsage{
					PromptTokens:     promptTokens,
					CompletionTokens: completionTokens,
					TotalTokens:      totalTokens,
				}

				s.streamingUsageCache.Store(requestID, newUsage)

				return newUsage, false, nil
			}
		}
	}

	return existingUsage, false, nil
}

func (s *Server) HandleResponseBody(ctx context.Context, requestID string, req *extProcPb.ProcessingRequest, user utils.User, rpm int64, model string, stream bool, traceTerm int64, hasCompleted bool) (*extProcPb.ProcessingResponse, bool) {
	b := req.Request.(*extProcPb.ProcessingRequest_ResponseBody)
	var res openai.ChatCompletion
	var usage openai.CompletionUsage
	var promptTokens, completionTokens int64
	var headers []*configPb.HeaderValueOption
	complete := hasCompleted
	routerCtx, _ := ctx.(*types.RoutingContext)

	timingObj, exists := utils.RequestTimings.Load(requestID)
	var timing *RequestTiming
	if exists {
		timing = timingObj.(*RequestTiming)
	}
	currentTime := time.Now()
	if timing != nil {
		if stream {
			usage_, complete, errorResponse := s.handleStreamingResponse(requestID, b.ResponseBody.GetBody())
			usage = usage_
			if errorResponse != nil {
				return errorResponse, complete
			}
		} else {
			buf, _ := s.requestBuffers.LoadOrStore(requestID, &bytes.Buffer{})
			buffer := buf.(*bytes.Buffer)
			buffer.Write(b.ResponseBody.Body)
			if timing.firstTokenTime.IsZero() && b.ResponseBody.EndOfStream {
				timing.firstTokenTime = currentTime
			}
			if !b.ResponseBody.EndOfStream {
				return &extProcPb.ProcessingResponse{
					Response: &extProcPb.ProcessingResponse_ResponseBody{
						ResponseBody: &extProcPb.BodyResponse{
							Response: &extProcPb.CommonResponse{},
						},
					},
				}, complete
			}
			finalBody := buffer.Bytes()
			s.requestBuffers.Delete(requestID)
			if err := json.Unmarshal(finalBody, &res); err != nil {
				klog.ErrorS(err, "error to unmarshal response", "requestID", requestID)
				complete = true
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorResponseUnmarshal, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			} else if len(res.Model) == 0 {
				msg := ErrorUnknownResponse.Error()
				responseBodyContent := string(finalBody)
				if len(responseBodyContent) != 0 {
					msg = responseBodyContent
				}
				klog.ErrorS(nil, "unexpected response", "requestID", requestID)
				complete = true
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorResponseUnknown, RawValue: []byte("true"),
					}}},
					msg), complete
			}
			usage = res.Usage
		}
		if b.ResponseBody.EndOfStream {
			// if routerCtx.Algorithm == "prefix-cache-and-load" {
			ret := utils.DecrementNumDecodeTokensForPod(routerCtx.TargetAddressWithoutPort(), int(timing.totalTokenCount))
			klog.V(5).Infof("DecrementNumDecodeTokensForPod(%s) by %d, %d", routerCtx.TargetAddressWithoutPort(), timing.totalTokenCount, ret)
			klog.Infof("Calling calculateTimingMetrics, requestID: %s, timing.decodeTokenCount: %d, timing.prefillTokenCount: %d", requestID, timing.decodeTokenCount, timing.prefillTokenCount)
			timingHeaders := s.calculateTimingMetrics(timing, currentTime, requestID, routerCtx, stream, usage.PromptTokens, usage.CompletionTokens, usage.TotalTokens)
			headers = append(headers, timingHeaders...)
			// }
			utils.RequestTimings.Delete(requestID)
			s.routingContexts.Delete(requestID)
		}
	}
	if usage.TotalTokens > 0 {
		complete = true
		promptTokens = usage.PromptTokens
		completionTokens = usage.CompletionTokens
		if user.Name != "" {
			tpm, err := s.ratelimiter.Incr(ctx, fmt.Sprintf("%v_TPM_CURRENT", user), usage.TotalTokens)
			if err != nil {
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorIncrTPM, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			}
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateRPM,
						RawValue: []byte(fmt.Sprintf("%d", rpm)),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateTPM,
						RawValue: []byte(fmt.Sprintf("%d", tpm)),
					},
				},
			)
		}
		if routerCtx != nil {
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPod,
						RawValue: []byte(routerCtx.TargetAddress()),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderRequestID,
						RawValue: []byte(requestID),
					},
				},
			)
		}
	}

	defer func() {
		if !hasCompleted && complete {
			s.cache.DoneRequestTrace(routerCtx, requestID, model, promptTokens, completionTokens, traceTerm)
			if routerCtx != nil {
				routerCtx.Delete()
			}
		}
	}()

	if stream {
		t := &http.Response{
			Body: io.NopCloser(bytes.NewReader(b.ResponseBody.GetBody())),
		}
		streaming := ssestream.NewStream[openai.ChatCompletionChunk](ssestream.NewDecoder(t), nil)
		defer func() {
			_ = streaming.Close()
		}()
		for streaming.Next() {
			evt := streaming.Current()
			if len(evt.Choices) == 0 {
				// Do not overwrite model, res can be empty.
				usage = evt.Usage
			}
		}
		if err := streaming.Err(); err != nil {
			klog.ErrorS(err, "error to unmarshal response", "requestID", requestID, "responseBody", string(b.ResponseBody.GetBody()))
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorStreaming, RawValue: []byte("true"),
				}}},
				err.Error()), complete
		}
	} else {
		buf, _ := requestBuffers.LoadOrStore(requestID, &bytes.Buffer{})
		buffer := buf.(*bytes.Buffer)
		buffer.Write(b.ResponseBody.Body)
		if !b.ResponseBody.EndOfStream {
			return &extProcPb.ProcessingResponse{
				Response: &extProcPb.ProcessingResponse_ResponseBody{
					ResponseBody: &extProcPb.BodyResponse{
						Response: &extProcPb.CommonResponse{},
					},
				},
			}, complete
		}
		finalBody := buffer.Bytes()
		requestBuffers.Delete(requestID)
		if err := json.Unmarshal(finalBody, &res); err != nil {
			klog.ErrorS(err, "error to unmarshal response", "requestID", requestID, "responseBody", string(b.ResponseBody.GetBody()))
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorResponseUnmarshal, RawValue: []byte("true"),
				}}},
				err.Error()), complete
		} else if len(res.Model) == 0 {
			msg := ErrorUnknownResponse.Error()
			responseBodyContent := string(b.ResponseBody.GetBody())
			if len(responseBodyContent) != 0 {
				msg = responseBodyContent
			}
			klog.ErrorS(err, "unexpected response", "requestID", requestID, "responseBody", responseBodyContent)
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorResponseUnknown, RawValue: []byte("true"),
				}}},
				msg), complete
		}
		// Do not overwrite model, res can be empty.
		usage = res.Usage
	}

	var requestEnd string
	if usage.TotalTokens != 0 {
		complete = true
		// Update promptTokens and completeTokens
		promptTokens = usage.PromptTokens
		completionTokens = usage.CompletionTokens
		// Count token per user.
		if user.Name != "" {
			tpm, err := s.ratelimiter.Incr(ctx, fmt.Sprintf("%v_TPM_CURRENT", user), res.Usage.TotalTokens)
			if err != nil {
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorIncrTPM, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			}

			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateRPM,
						RawValue: []byte(fmt.Sprintf("%d", rpm)),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateTPM,
						RawValue: []byte(fmt.Sprintf("%d", tpm)),
					},
				},
			)
			requestEnd = fmt.Sprintf(requestEnd+"rpm: %s, tpm: %s, ", rpm, tpm)
		}
		if routerCtx != nil {
			targetPodName := routerCtx.TargetName()
			targetPodIP := routerCtx.TargetAddress()
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPod,
						RawValue: []byte(targetPodIP),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderRequestID,
						RawValue: []byte(requestID),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPodName,
						RawValue: []byte(targetPodName),
					},
				},
			)
			requestEnd = fmt.Sprintf(requestEnd+"targetPod: %s", targetPodIP)
		}

		klog.Infof("request end, requestID: %s - %s", requestID, requestEnd)
	} else if b.ResponseBody.EndOfStream {
		complete = true
	}

	// klog.Infof("SetHeaders: %s", headers)

	return &extProcPb.ProcessingResponse{
		Response: &extProcPb.ProcessingResponse_ResponseBody{
			ResponseBody: &extProcPb.BodyResponse{
				Response: &extProcPb.CommonResponse{
					HeaderMutation: &extProcPb.HeaderMutation{
						SetHeaders: headers,
					},
				},
			},
		},
	}, complete
}

// MetricsData holds all the performance metrics for a request
type MetricsData struct {
	TTFT               int64              `json:"ttft_ms"`
	TPOT               int64              `json:"tpot_ms"`
	E2ELatency         int64              `json:"e2e_latency_ms"`
	KVCacheHitRatio    float64            `json:"kv_cache_hit_ratio"`
	AllPodsRatios      map[string]float64 `json:"all_pods_ratios,omitempty"`
	InflightRequests   map[string]int     `json:"inflight_requests,omitempty"`
	GPUKVCacheUsage    map[string]float64 `json:"gpu_kv_cache_usage,omitempty"`
	CPUKVCacheUsage    map[string]float64 `json:"cpu_kv_cache_usage,omitempty"`
	NumRequestsRunning map[string]float64 `json:"num_requests_running,omitempty"`
	NumRequestsWaiting map[string]float64 `json:"num_requests_waiting,omitempty"`
	InputTokens        int64              `json:"input_tokens"`
	OutputTokens       int64              `json:"output_tokens"`
	TotalTokens        int64              `json:"total_tokens"`
	SelectedPod        string             `json:"selected_pod"`
}

// Helper function to add a JSON metric to headers
func addMetricToHeaders(headers []*configPb.HeaderValueOption, key string, data interface{}, lock *sync.RWMutex) ([]*configPb.HeaderValueOption, string) {
	lock.RLock()
	defer lock.RUnlock()
	jsonData, err := json.Marshal(data)
	jsonStr := "{}"
	if err == nil {
		jsonStr = string(jsonData)
		headers = append(headers, &configPb.HeaderValueOption{
			Header: &configPb.HeaderValue{
				Key:      key,
				RawValue: jsonData,
			},
		})
	}
	return headers, jsonStr
}

func (s *Server) calculateTimingMetrics(timing *RequestTiming, currentTime time.Time, requestID string, routingCtx *types.RoutingContext, stream bool, numInputTokens int64, numOutputTokens int64, numTotalTokens int64) []*configPb.HeaderValueOption {
	// Calculate basic timing metrics
	ttftMs := int64(0)
	if !timing.firstTokenTime.IsZero() {
		ttftMs = timing.firstTokenTime.Sub(timing.startTime).Milliseconds()
	}

	avgTpotMs := int64(0)
	totalGenerationTimeMs := int64(0)
	if !timing.firstTokenTime.IsZero() {
		totalGenerationTimeMs = currentTime.Sub(timing.firstTokenTime).Milliseconds()
		effectiveTokenCount := int64(0)
		if stream && timing.decodeTokenCount > 1 {
			effectiveTokenCount = int64(timing.decodeTokenCount - 1) // Exclude first token
		} else if numOutputTokens > 1 {
			effectiveTokenCount = numOutputTokens - 1
		}
		if effectiveTokenCount > 0 {
			avgTpotMs = totalGenerationTimeMs / effectiveTokenCount
			klog.Infof("ttftMS:%d, avgTpotMs: %d, totalGenerationTimeMs: %d, effectiveTokenCount: %d", ttftMs, avgTpotMs, totalGenerationTimeMs, effectiveTokenCount)
		}
	}

	end_to_end_latency_in_ms := time.Since(timing.startTime).Milliseconds()

	// Initialize headers with basic metrics
	headers := []*configPb.HeaderValueOption{
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderTTFT,
				RawValue: []byte(fmt.Sprintf("%d", ttftMs)),
			},
		},
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderTPOT,
				RawValue: []byte(fmt.Sprintf("%d", avgTpotMs)),
			},
		},
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderE2ELatency,
				RawValue: []byte(fmt.Sprintf("%d", end_to_end_latency_in_ms)),
			},
		},
	}

	// Prepare for JSON strings to use in logging
	var jsonStrings = make(map[string]string)

	// 1. KV cache hit ratios
	allPodsKvCacheHitRatios := utils.GetAllPodsKVCacheHitRatios(requestID)
	headers, jsonStrings["allPodsKvCacheHitRatios"] = addMetricToHeaders(headers, HeaderKVCacheHitRatioAllPods, allPodsKvCacheHitRatios, utils.GetrequestAllPodsKVCacheMutex())
	utils.CleanupKVCacheHitRatio(requestID)

	// 2. Inflight requests
	numInflightRequestsAllPods := utils.GetInflightRequestsForAllPods(requestID)
	headers, jsonStrings["numInflightRequestsAllPods"] = addMetricToHeaders(headers, HeaderNumInflightRequestsAllPods, numInflightRequestsAllPods, utils.GetrequestInflightMutex())
	utils.DecrementNumInflightForPod(requestID, routingCtx.TargetAddressWithoutPort())
	utils.CleanupInflightRequests(requestID)

	// 3. GPU KV cache usage
	vllmGPUKVCacheUsage, err := utils.GetvLLMGPUKVCacheUsageForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmGPUKVCacheUsage"] = addMetricToHeaders(headers, HeadervLLMGPUKVCacheUsage, vllmGPUKVCacheUsage, utils.GetvllmGPUKVCacheUsageMutex())
		utils.CleanupvLLMGPUKVCacheUsage(requestID)
	} else {
		jsonStrings["vllmGPUKVCacheUsage"] = "{}"
	}

	// 4. CPU KV cache usage
	vllmCPUKVCacheUsage, err := utils.GetvLLMCPUKVCacheUsageForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmCPUKVCacheUsage"] = addMetricToHeaders(headers, HeadervLLMCPUKVCacheUsage, vllmCPUKVCacheUsage, utils.GetvllmCPUKVCacheUsageMutex())
		utils.CleanupvLLMCPUKVCacheUsage(requestID)
	} else {
		jsonStrings["vllmCPUKVCacheUsage"] = "{}"
	}

	// 5. Number of running requests
	vllmNumRequestsRunning, err := utils.GetvLLMNumRequestsRunningForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmNumRequestsRunning"] = addMetricToHeaders(headers, HeadervLLMNumRunningRequests, vllmNumRequestsRunning, utils.GetvllmNumRequestsRunningMutex())
		utils.CleanupvLLMNumRequestsRunning(requestID)
	} else {
		jsonStrings["vllmNumRequestsRunning"] = "{}"
	}

	// 6. Number of waiting requests
	vllmNumRequestWaiting, err := utils.GetvLLMNumRequestsWaitingForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmNumRequestWaiting"] = addMetricToHeaders(headers, HeadervLLMNumwWaitingRequests, vllmNumRequestWaiting, utils.GetvllmNumRequestsWaitingMutex())
		utils.CleanupvLLMNumRequestsWaiting(requestID)
	} else {
		jsonStrings["vllmNumRequestWaiting"] = "{}"
	}

	numPrefillTokensForAllPods := utils.GetNumPrefillTokensForAllPods()
	utils.CleanupNumPrefillTokensForRequest(requestID)
	headers, jsonStrings["numPrefillTokensForAllPods"] = addMetricToHeaders(headers, HeaderNumPrefillTokensForAllPods, numPrefillTokensForAllPods, utils.GetpodTotalPrefillTokensMutex())

	numDecodeTokensForAllPods := utils.GetNumDecodeTokensForAllPods()
	utils.CleanupNumDecodeTokensForRequest(requestID)
	headers, jsonStrings["numDecodeTokensForAllPods"] = addMetricToHeaders(headers, HeaderNumDecodeTokensForAllPods, numDecodeTokensForAllPods, utils.GetpodTotalDecodeTokensMutex())

	// Get selected pod
	selectedPodIP := "unknown"
	if routingCtx != nil {
		selectedPodIP = routingCtx.TargetAddressWithoutPort()
	}

	ts := time.Now()
	podDetailedMetrics := utils.GetAndCleanupRequestPodMetrics(requestID)
	klog.Infof("GetAndCleanupRequestPodMetrics took %d, %s, %s", time.Since(ts).Milliseconds(), requestID, selectedPodIP)
	headers, jsonStrings["podMetricsLastSecond"] = addMetricToHeaders(headers, HeaderPodDetailedMetrics, podDetailedMetrics, utils.MetricsTracker.GetMutex())

	klog.Infof("**@latency_metrics@requestID@%s@request_start_time@%d@request_end_time@%d@selectedpod@%s@ttft@%d@avg_tpot@%d@total_decode_time@%d@e2e@%d@numInputTokens@%d@numOutputTokens@%d@numTotalTokens@%d@allPodsKvCacheHitRatios@%s@numInflightRequestsAllPods@%s@vllmGPUKVCacheUsage@%s@vllmCPUKVCacheUsage@%s@vllmNumRequestsRunning@%s@vllmNumRequestsWaiting@%s@podMetricsLastSecond@%s@numPrefillTokensForAllPods@%s@numDecodeTokensForAllPods@%s",
		requestID,
		timing.startTime.UnixMicro(),
		currentTime.UnixMicro(),
		selectedPodIP,
		ttftMs,
		avgTpotMs,
		totalGenerationTimeMs,
		end_to_end_latency_in_ms,
		numInputTokens,
		numOutputTokens,
		numTotalTokens,
		jsonStrings["allPodsKvCacheHitRatios"],
		jsonStrings["numInflightRequestsAllPods"],
		jsonStrings["vllmGPUKVCacheUsage"],
		jsonStrings["vllmCPUKVCacheUsage"],
		jsonStrings["vllmNumRequestsRunning"],
		jsonStrings["vllmNumRequestWaiting"],
		jsonStrings["podMetricsLastSecond"],
		jsonStrings["numPrefillTokensForAllPods"],
		jsonStrings["numDecodeTokensForAllPods"],
	)

	return headers
}

///////////////////////////////////////////////////////////////////////////

// Helper functions for metrics tracking
// IsMetricsEnabled returns whether metrics collection is enabled
func (s *Server) IsMetricsEnabled() bool {
	return utils.MetricsEnabled.Load()
}

// EnableMetrics enables metrics collection
func (s *Server) EnableMetrics() {
	utils.MetricsEnabled.Store(true)
	klog.Info("Metrics collection enabled")
}

// DisableMetrics disables metrics collection
func (s *Server) DisableMetrics() {
	utils.MetricsEnabled.Store(false)
	klog.Info("Metrics collection disabled")
}
