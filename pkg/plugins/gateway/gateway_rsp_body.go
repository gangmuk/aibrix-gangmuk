/*
Copyright 2024 The Aibrix Team.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package gateway

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/openai/openai-go"
	"github.com/openai/openai-go/packages/ssestream"
	"k8s.io/klog/v2"

	configPb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
	extProcPb "github.com/envoyproxy/go-control-plane/envoy/service/ext_proc/v3"
	envoyTypePb "github.com/envoyproxy/go-control-plane/envoy/type/v3"
	"github.com/vllm-project/aibrix/pkg/types"
	"github.com/vllm-project/aibrix/pkg/utils"
)

func (s *Server) handleStreamingResponse(requestID string, responseBody []byte) (openai.CompletionUsage, bool, *extProcPb.ProcessingResponse) {
	lines := strings.Split(string(responseBody), "\n")
	existingUsageRaw, _ := s.streamingUsageCache.LoadOrStore(requestID, openai.CompletionUsage{})
	existingUsage := existingUsageRaw.(openai.CompletionUsage)
	timingObj, exists := s.requestTimings.Load(requestID)
	if !exists {
		return existingUsage, false, nil
	}
	timing := timingObj.(*RequestTiming)
	prefill_token_count := int(timing.prefillTokenCount)
	currentTime := time.Now()
	routerCtxObj, exists := s.routingContexts.Load(requestID)
	if !exists {
		return existingUsage, false, nil
	}
	routerCtx := routerCtxObj.(*types.RoutingContext)
	selectedPodIP := routerCtx.TargetAddressWithoutPort()
	podIPWithoutPort := routerCtx.TargetAddressWithoutPort()
	t := &http.Response{
		Body: io.NopCloser(bytes.NewReader(responseBody)),
	}
	streaming := ssestream.NewStream[openai.ChatCompletionChunk](ssestream.NewDecoder(t), nil)
	for streaming.Next() {
		evt := streaming.Current()
		if len(evt.Choices) > 0 && evt.Choices[0].Delta.Content != "" {
			// First token response
			if timing.firstTokenTime.IsZero() {
				timing.IsPrefill = false
				timing.decodeTokenCount = 1 // one token is generated by stream mode for the first response
				timing.firstTokenTime = currentTime
				timing.lastTokenTime = currentTime
				ttftMs := currentTime.Sub(timing.startTime).Milliseconds()
				if ttftMs > 0 {
					s.metricsTracker.AddPodMetric(selectedPodIP, PodMetric{
						requestID:       requestID,
						Timestamp:       currentTime,
						TTFT:            ttftMs,
						TPOT:            0,
						PrefillTokenNum: int64(prefill_token_count),
						DecodeTokenNum:  1,
					})
				}
				klog.V(5).InfoS("First token received", "requestID", requestID, "ttft_ms", ttftMs)

				ret := utils.DecrementNumPrefillTokensForPod(podIPWithoutPort, prefill_token_count)
				klog.V(5).Infof("DecrementNumPrefillTokensForPod(%s) by %d, %d", podIPWithoutPort, prefill_token_count, ret)

				ret = utils.IncrementNumDecodeTokensForPod(podIPWithoutPort, prefill_token_count+1)
				klog.V(5).Infof("IncrementNumDecodeTokensForPod(%s) by %d, %d", podIPWithoutPort, prefill_token_count+1, ret)

				ret = utils.IncrementNumDecodeTokensForRequest(requestID, prefill_token_count+1)
				klog.V(5).Infof("IncrementNumDecodeTokensForRequest(%s) by %d, %d", requestID, prefill_token_count+1, ret)
			} else { // Decode token response
				if timing.firstDecodeTokenTime.IsZero() {
					// First decode token
					timing.firstDecodeTokenTime = currentTime
					klog.V(5).Infof("First decode token received, requestID,%s, timing.prefillTokenCount.%d", requestID, timing.prefillTokenCount)
				}
				timing.decodeTokenCount++
				ret := utils.IncrementNumDecodeTokensForRequest(requestID, 1)
				klog.V(5).Infof("IncrementNumDecodeTokensForRequest(%s) by 1, %d", requestID, ret)

				ret = utils.IncrementNumDecodeTokensForPod(podIPWithoutPort, 1)
				klog.V(5).Infof("IncrementNumDecodeTokensForPod(%s) by 1, %d", podIPWithoutPort, ret)

				timeSincePrevToken := currentTime.Sub(timing.lastTokenTime).Milliseconds()
				if timeSincePrevToken > 0 {
					s.metricsTracker.AddPodMetric(selectedPodIP, PodMetric{
						requestID:       requestID,
						Timestamp:       currentTime,
						TTFT:            0,
						TPOT:            timeSincePrevToken,
						PrefillTokenNum: 0,
						DecodeTokenNum:  timing.decodeTokenCount,
					})
				}
			}
			klog.V(5).Infof("Token received, requestID: %s, timing.decodeTokenCount: %d, timing.prefillTokenCount: %d", requestID, timing.decodeTokenCount, timing.prefillTokenCount)
			timing.lastTokenTime = currentTime
			timing.totalTokenCount++
		}
	}

	if err := streaming.Err(); err != nil {
		klog.ErrorS(err, "error processing streaming response", "requestID", requestID)

		complete := true
		errorResponse := generateErrorResponse(
			envoyTypePb.StatusCode_InternalServerError,
			[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
				Key: HeaderErrorStreaming, RawValue: []byte("true"),
			}}},
			err.Error())

		return existingUsage, complete, errorResponse
	}

	for i := len(lines) - 1; i >= 0; i-- {
		line := strings.TrimSpace(lines[i])

		if !strings.HasPrefix(line, "data:") || line == "data: [DONE]" {
			continue
		}

		cleanLine := strings.TrimPrefix(line, "data: ")

		var chunk map[string]interface{}
		if err := json.Unmarshal([]byte(cleanLine), &chunk); err != nil {
			continue
		}

		if usageMap, ok := chunk["usage"].(map[string]interface{}); ok {
			promptTokens := int64(usageMap["prompt_tokens"].(float64))
			completionTokens := int64(usageMap["completion_tokens"].(float64))
			totalTokens := int64(usageMap["total_tokens"].(float64))

			if promptTokens > 0 || completionTokens > 0 || totalTokens > 0 {
				newUsage := openai.CompletionUsage{
					PromptTokens:     promptTokens,
					CompletionTokens: completionTokens,
					TotalTokens:      totalTokens,
				}

				s.streamingUsageCache.Store(requestID, newUsage)

				return newUsage, false, nil
			}
		}
	}

	return existingUsage, false, nil
}

func (s *Server) HandleResponseBody(ctx context.Context, requestID string, req *extProcPb.ProcessingRequest, user utils.User, rpm int64, model string, stream bool, traceTerm int64, hasCompleted bool) (*extProcPb.ProcessingResponse, bool) {
	b := req.Request.(*extProcPb.ProcessingRequest_ResponseBody)
	var res openai.ChatCompletion
	var usage openai.CompletionUsage
	var promptTokens, completionTokens int64
	var headers []*configPb.HeaderValueOption
	complete := hasCompleted
	routerCtx, _ := ctx.(*types.RoutingContext)

	timingObj, exists := s.requestTimings.Load(requestID)
	var timing *RequestTiming
	if exists {
		timing = timingObj.(*RequestTiming)
	}
	currentTime := time.Now()
	if timing != nil {
		if stream {
			usage_, complete, errorResponse := s.handleStreamingResponse(requestID, b.ResponseBody.GetBody())
			usage = usage_
			if errorResponse != nil {
				return errorResponse, complete
			}
		} else {
			buf, _ := s.requestBuffers.LoadOrStore(requestID, &bytes.Buffer{})
			buffer := buf.(*bytes.Buffer)
			buffer.Write(b.ResponseBody.Body)
			if timing.firstTokenTime.IsZero() && b.ResponseBody.EndOfStream {
				timing.firstTokenTime = currentTime
			}
			if !b.ResponseBody.EndOfStream {
				return &extProcPb.ProcessingResponse{
					Response: &extProcPb.ProcessingResponse_ResponseBody{
						ResponseBody: &extProcPb.BodyResponse{
							Response: &extProcPb.CommonResponse{},
						},
					},
				}, complete
			}
			finalBody := buffer.Bytes()
			s.requestBuffers.Delete(requestID)
			if err := json.Unmarshal(finalBody, &res); err != nil {
				klog.ErrorS(err, "error to unmarshal response", "requestID", requestID)
				complete = true
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorResponseUnmarshal, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			} else if len(res.Model) == 0 {
				msg := ErrorUnknownResponse.Error()
				responseBodyContent := string(finalBody)
				if len(responseBodyContent) != 0 {
					msg = responseBodyContent
				}
				klog.ErrorS(nil, "unexpected response", "requestID", requestID)
				complete = true
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorResponseUnknown, RawValue: []byte("true"),
					}}},
					msg), complete
			}
			usage = res.Usage
		}
		if b.ResponseBody.EndOfStream {
			// if routerCtx.Algorithm == "prefix-cache-and-load" {
			ret := utils.DecrementNumDecodeTokensForPod(routerCtx.TargetAddressWithoutPort(), int(timing.totalTokenCount))
			klog.V(5).Infof("DecrementNumDecodeTokensForPod(%s) by %d, %d", routerCtx.TargetAddressWithoutPort(), timing.totalTokenCount, ret)
			timingHeaders := s.calculateTimingMetrics(timing, currentTime, requestID, routerCtx, stream, usage.PromptTokens, usage.CompletionTokens, usage.TotalTokens)
			headers = append(headers, timingHeaders...)
			// }
			s.requestTimings.Delete(requestID)
			s.routingContexts.Delete(requestID)
		}
	}
	if usage.TotalTokens > 0 {
		complete = true
		promptTokens = usage.PromptTokens
		completionTokens = usage.CompletionTokens
		if user.Name != "" {
			tpm, err := s.ratelimiter.Incr(ctx, fmt.Sprintf("%v_TPM_CURRENT", user), usage.TotalTokens)
			if err != nil {
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorIncrTPM, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			}
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateRPM,
						RawValue: []byte(fmt.Sprintf("%d", rpm)),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateTPM,
						RawValue: []byte(fmt.Sprintf("%d", tpm)),
					},
				},
			)
		}
		if routerCtx != nil {
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPod,
						RawValue: []byte(routerCtx.TargetAddress()),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderRequestID,
						RawValue: []byte(requestID),
					},
				},
			)
		}
	}

	defer func() {
		if !hasCompleted && complete {
			s.cache.DoneRequestTrace(routerCtx, requestID, model, promptTokens, completionTokens, traceTerm)
			if routerCtx != nil {
				routerCtx.Delete()
			}
		}
	}()

	if stream {
		t := &http.Response{
			Body: io.NopCloser(bytes.NewReader(b.ResponseBody.GetBody())),
		}
		streaming := ssestream.NewStream[openai.ChatCompletionChunk](ssestream.NewDecoder(t), nil)
		defer func() {
			_ = streaming.Close()
		}()
		for streaming.Next() {
			evt := streaming.Current()
			if len(evt.Choices) == 0 {
				// Do not overwrite model, res can be empty.
				usage = evt.Usage
			}
		}
		if err := streaming.Err(); err != nil {
			klog.ErrorS(err, "error to unmarshal response", "requestID", requestID, "responseBody", string(b.ResponseBody.GetBody()))
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorStreaming, RawValue: []byte("true"),
				}}},
				err.Error()), complete
		}
	} else {
		buf, _ := requestBuffers.LoadOrStore(requestID, &bytes.Buffer{})
		buffer := buf.(*bytes.Buffer)
		buffer.Write(b.ResponseBody.Body)
		if !b.ResponseBody.EndOfStream {
			return &extProcPb.ProcessingResponse{
				Response: &extProcPb.ProcessingResponse_ResponseBody{
					ResponseBody: &extProcPb.BodyResponse{
						Response: &extProcPb.CommonResponse{},
					},
				},
			}, complete
		}
		finalBody := buffer.Bytes()
		requestBuffers.Delete(requestID)
		if err := json.Unmarshal(finalBody, &res); err != nil {
			klog.ErrorS(err, "error to unmarshal response", "requestID", requestID, "responseBody", string(b.ResponseBody.GetBody()))
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorResponseUnmarshal, RawValue: []byte("true"),
				}}},
				err.Error()), complete
		} else if len(res.Model) == 0 {
			msg := ErrorUnknownResponse.Error()
			responseBodyContent := string(b.ResponseBody.GetBody())
			if len(responseBodyContent) != 0 {
				msg = responseBodyContent
			}
			klog.ErrorS(err, "unexpected response", "requestID", requestID, "responseBody", responseBodyContent)
			complete = true
			return generateErrorResponse(
				envoyTypePb.StatusCode_InternalServerError,
				[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
					Key: HeaderErrorResponseUnknown, RawValue: []byte("true"),
				}}},
				msg), complete
		}
		// Do not overwrite model, res can be empty.
		usage = res.Usage
	}

	var requestEnd string
	if usage.TotalTokens != 0 {
		complete = true
		// Update promptTokens and completeTokens
		promptTokens = usage.PromptTokens
		completionTokens = usage.CompletionTokens
		// Count token per user.
		if user.Name != "" {
			tpm, err := s.ratelimiter.Incr(ctx, fmt.Sprintf("%v_TPM_CURRENT", user), res.Usage.TotalTokens)
			if err != nil {
				return generateErrorResponse(
					envoyTypePb.StatusCode_InternalServerError,
					[]*configPb.HeaderValueOption{{Header: &configPb.HeaderValue{
						Key: HeaderErrorIncrTPM, RawValue: []byte("true"),
					}}},
					err.Error()), complete
			}

			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateRPM,
						RawValue: []byte(fmt.Sprintf("%d", rpm)),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderUpdateTPM,
						RawValue: []byte(fmt.Sprintf("%d", tpm)),
					},
				},
			)
			requestEnd = fmt.Sprintf(requestEnd+"rpm: %s, tpm: %s, ", rpm, tpm)
		}
		if routerCtx != nil {
			targetPodName := routerCtx.TargetName()
			targetPodIP := routerCtx.TargetAddress()
			headers = append(headers,
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPod,
						RawValue: []byte(targetPodIP),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderRequestID,
						RawValue: []byte(requestID),
					},
				},
				&configPb.HeaderValueOption{
					Header: &configPb.HeaderValue{
						Key:      HeaderTargetPodName,
						RawValue: []byte(targetPodName),
					},
				},
			)
			requestEnd = fmt.Sprintf(requestEnd+"targetPod: %s", targetPodIP)
		}

		klog.Infof("request end, requestID: %s - %s", requestID, requestEnd)
	} else if b.ResponseBody.EndOfStream {
		complete = true
	}

	// klog.Infof("SetHeaders: %s", headers)

	return &extProcPb.ProcessingResponse{
		Response: &extProcPb.ProcessingResponse_ResponseBody{
			ResponseBody: &extProcPb.BodyResponse{
				Response: &extProcPb.CommonResponse{
					HeaderMutation: &extProcPb.HeaderMutation{
						SetHeaders: headers,
					},
				},
			},
		},
	}, complete
}

// MetricsData holds all the performance metrics for a request
type MetricsData struct {
	TTFT               int64              `json:"ttft_ms"`
	TPOT               int64              `json:"tpot_ms"`
	E2ELatency         int64              `json:"e2e_latency_ms"`
	KVCacheHitRatio    float64            `json:"kv_cache_hit_ratio"`
	AllPodsRatios      map[string]float64 `json:"all_pods_ratios,omitempty"`
	InflightRequests   map[string]int     `json:"inflight_requests,omitempty"`
	GPUKVCacheUsage    map[string]float64 `json:"gpu_kv_cache_usage,omitempty"`
	CPUKVCacheUsage    map[string]float64 `json:"cpu_kv_cache_usage,omitempty"`
	NumRequestsRunning map[string]float64 `json:"num_requests_running,omitempty"`
	NumRequestsWaiting map[string]float64 `json:"num_requests_waiting,omitempty"`
	InputTokens        int64              `json:"input_tokens"`
	OutputTokens       int64              `json:"output_tokens"`
	TotalTokens        int64              `json:"total_tokens"`
	SelectedPod        string             `json:"selected_pod"`
}

// Helper function to add a JSON metric to headers
func addMetricToHeaders(headers []*configPb.HeaderValueOption, key string, data interface{}, lock *sync.RWMutex) ([]*configPb.HeaderValueOption, string) {
	lock.RLock()
	defer lock.RUnlock()
	jsonData, err := json.Marshal(data)
	jsonStr := "{}"
	if err == nil {
		jsonStr = string(jsonData)
		headers = append(headers, &configPb.HeaderValueOption{
			Header: &configPb.HeaderValue{
				Key:      key,
				RawValue: jsonData,
			},
		})
	}
	return headers, jsonStr
}

func (s *Server) calculateTimingMetrics(timing *RequestTiming, currentTime time.Time, requestID string, routingCtx *types.RoutingContext, stream bool, numInputTokens int64, numOutputTokens int64, numTotalTokens int64) []*configPb.HeaderValueOption {
	// Calculate basic timing metrics
	ttftMs := int64(0)
	if !timing.firstTokenTime.IsZero() {
		ttftMs = timing.firstTokenTime.Sub(timing.startTime).Milliseconds()
	}

	avgTpotMs := int64(0)
	totalGenerationTimeMs := int64(0)
	if !timing.firstTokenTime.IsZero() {
		totalGenerationTimeMs = currentTime.Sub(timing.firstTokenTime).Milliseconds()
		effectiveTokenCount := int64(0)
		if stream && timing.decodeTokenCount > 1 {
			effectiveTokenCount = int64(timing.decodeTokenCount - 1) // Exclude first token
		} else if numOutputTokens > 1 {
			effectiveTokenCount = numOutputTokens - 1
		}
		if effectiveTokenCount > 0 {
			avgTpotMs = totalGenerationTimeMs / effectiveTokenCount
			klog.Infof("ttftMS:%d, avgTpotMs: %d, totalGenerationTimeMs: %d, effectiveTokenCount: %d", ttftMs, avgTpotMs, totalGenerationTimeMs, effectiveTokenCount)
		}
	}

	end_to_end_latency_in_ms := time.Since(timing.startTime).Milliseconds()

	// Initialize headers with basic metrics
	headers := []*configPb.HeaderValueOption{
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderTTFT,
				RawValue: []byte(fmt.Sprintf("%d", ttftMs)),
			},
		},
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderTPOT,
				RawValue: []byte(fmt.Sprintf("%d", avgTpotMs)),
			},
		},
		{
			Header: &configPb.HeaderValue{
				Key:      HeaderE2ELatency,
				RawValue: []byte(fmt.Sprintf("%d", end_to_end_latency_in_ms)),
			},
		},
	}

	// Prepare for JSON strings to use in logging
	var jsonStrings = make(map[string]string)

	// 1. KV cache hit ratios
	allPodsKvCacheHitRatios := utils.GetAllPodsKVCacheHitRatios(requestID)
	headers, jsonStrings["allPodsKvCacheHitRatios"] = addMetricToHeaders(headers, HeaderKVCacheHitRatioAllPods, allPodsKvCacheHitRatios, utils.GetrequestAllPodsKVCacheMutex())
	utils.CleanupKVCacheHitRatio(requestID)

	// 2. Inflight requests
	numInflightRequestsAllPods := utils.GetInflightRequestsForAllPods(requestID)
	headers, jsonStrings["numInflightRequestsAllPods"] = addMetricToHeaders(headers, HeaderNumInflightRequestsAllPods, numInflightRequestsAllPods, utils.GetrequestInflightMutex())
	utils.DecrementNumInflightForPod(requestID)
	utils.CleanupInflightRequests(requestID)

	// 3. GPU KV cache usage
	vllmGPUKVCacheUsage, err := utils.GetvLLMGPUKVCacheUsageForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmGPUKVCacheUsage"] = addMetricToHeaders(headers, HeadervLLMGPUKVCacheUsage, vllmGPUKVCacheUsage, utils.GetvllmGPUKVCacheUsageMutex())
		utils.CleanupvLLMGPUKVCacheUsage(requestID)
	} else {
		jsonStrings["vllmGPUKVCacheUsage"] = "{}"
	}

	// 4. CPU KV cache usage
	vllmCPUKVCacheUsage, err := utils.GetvLLMCPUKVCacheUsageForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmCPUKVCacheUsage"] = addMetricToHeaders(headers, HeadervLLMCPUKVCacheUsage, vllmCPUKVCacheUsage, utils.GetvllmCPUKVCacheUsageMutex())
		utils.CleanupvLLMCPUKVCacheUsage(requestID)
	} else {
		jsonStrings["vllmCPUKVCacheUsage"] = "{}"
	}

	// 5. Number of running requests
	vllmNumRequestsRunning, err := utils.GetvLLMNumRequestsRunningForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmNumRequestsRunning"] = addMetricToHeaders(headers, HeadervLLMNumRunningRequests, vllmNumRequestsRunning, utils.GetvllmNumRequestsRunningMutex())
		utils.CleanupvLLMNumRequestsRunning(requestID)
	} else {
		jsonStrings["vllmNumRequestsRunning"] = "{}"
	}

	// 6. Number of waiting requests
	vllmNumRequestWaiting, err := utils.GetvLLMNumRequestsWaitingForTheRequestForAllPods(requestID)
	if err == nil {
		headers, jsonStrings["vllmNumRequestWaiting"] = addMetricToHeaders(headers, HeadervLLMNumwWaitingRequests, vllmNumRequestWaiting, utils.GetvllmNumRequestsWaitingMutex())
		utils.CleanupvLLMNumRequestsWaiting(requestID)
	} else {
		jsonStrings["vllmNumRequestWaiting"] = "{}"
	}

	numPrefillTokensForAllPods := utils.GetNumPrefillTokensForAllPods()
	utils.CleanupNumPrefillTokensForRequest(requestID)
	headers, jsonStrings["numPrefillTokensForAllPods"] = addMetricToHeaders(headers, HeaderNumPrefillTokensForAllPods, numPrefillTokensForAllPods, utils.GetpodTotalPrefillTokensMutex())

	numDecodeTokensForAllPods := utils.GetNumDecodeTokensForAllPods()
	utils.CleanupNumDecodeTokensForRequest(requestID)
	headers, jsonStrings["numDecodeTokensForAllPods"] = addMetricToHeaders(headers, HeaderNumDecodeTokensForAllPods, numDecodeTokensForAllPods, utils.GetpodTotalDecodeTokensMutex())

	// Get selected pod
	selectedPodIP := "unknown"
	if routingCtx != nil {
		selectedPodIP = routingCtx.TargetAddressWithoutPort()
	}

	// 7. Pod detailed metrics
	log_window_end_time := time.Now()
	log_window_start_time := time.Now().Add(-s.metricsTracker.windowSize)
	podDetailedMetrics := s.metricsTracker.GetDetailedMetrics(log_window_start_time, numInputTokens, numOutputTokens, numTotalTokens)
	headers, jsonStrings["podMetricsLastSecond"] = addMetricToHeaders(headers, HeaderPodDetailedMetrics, podDetailedMetrics, &s.metricsTracker.mutex)

	klog.Infof("**@latency_metrics@requestID@%s@request_start_time@%d@request_end_time@%d@selectedpod@%s@ttft@%d@avg_tpot@%d@total_decode_time@%d@e2e@%d@numInputTokens@%d@numOutputTokens@%d@numTotalTokens@%d@allPodsKvCacheHitRatios@%s@numInflightRequestsAllPods@%s@vllmGPUKVCacheUsage@%s@vllmCPUKVCacheUsage@%s@vllmNumRequestsRunning@%s@vllmNumRequestsWaiting@%s@podMetricsLastSecond@%s@log_window_start_time@%d@log_window_end_time@%d@numPrefillTokensForAllPods@%s@numDecodeTokensForAllPods@%s",
		requestID,
		timing.startTime.UnixMicro(),
		currentTime.UnixMicro(),
		selectedPodIP,
		ttftMs,
		avgTpotMs,
		totalGenerationTimeMs,
		end_to_end_latency_in_ms,
		numInputTokens,
		numOutputTokens,
		numTotalTokens,
		jsonStrings["allPodsKvCacheHitRatios"],
		jsonStrings["numInflightRequestsAllPods"],
		jsonStrings["vllmGPUKVCacheUsage"],
		jsonStrings["vllmCPUKVCacheUsage"],
		jsonStrings["vllmNumRequestsRunning"],
		jsonStrings["vllmNumRequestWaiting"],
		jsonStrings["podMetricsLastSecond"],
		log_window_start_time.UnixMicro(),
		log_window_end_time.UnixMicro(),
		jsonStrings["numPrefillTokensForAllPods"],
		jsonStrings["numDecodeTokensForAllPods"],
	)

	return headers
}

////////////////////////////////////////////////////////////////////////////////////////////////

// PodDetailedMetrics provides detailed statistics for a pod's performance
type PodDetailedMetrics struct {
	// TTFT metrics
	AvgTTFT     float64 `json:"last_second_avg_ttft_ms"`
	MinTTFT     int64   `json:"last_second_min_ttft_ms"`
	MaxTTFT     int64   `json:"last_second_max_ttft_ms"`
	P50TTFT     int64   `json:"last_second_p50_ttft_ms"` // Median TTFT
	P90TTFT     int64   `json:"last_second_p90_ttft_ms"` // 90th percentile TTFT
	P95TTFT     int64   `json:"last_second_p95_ttft_ms"` // 95th percentile TTFT
	P99TTFT     int64   `json:"last_second_p99_ttft_ms"` // 99th percentile TTFT
	TTFTSamples int     `json:"last_second_ttft_samples"`

	// TPOT metrics
	AvgTPOT     float64 `json:"last_second_avg_tpot_ms"`
	MinTPOT     int64   `json:"last_second_min_tpot_ms"`
	MaxTPOT     int64   `json:"last_second_max_tpot_ms"`
	P50TPOT     int64   `json:"last_second_p50_tpot_ms"` // Median TPOT
	P90TPOT     int64   `json:"last_second_p90_tpot_ms"` // 90th percentile TPOT
	P95TPOT     int64   `json:"last_second_p95_tpot_ms"` // 95th percentile TPOT
	P99TPOT     int64   `json:"last_second_p99_tpot_ms"` // 99th percentile TPOT
	TPOTSamples int     `json:"last_second_tpot_samples"`

	// // Token position-based TPOT metrics (average TPOT for tokens 2-10)
	EarlyTokensTPOT float64 `json:"last_second_early_tokens_tpot_ms"`
	MidTokensTPOT   float64 `json:"last_second_mid_tokens_tpot_ms"`
	LateTokensTPOT  float64 `json:"last_second_late_tokens_tpot_ms"`

	// Overall metrics
	TotalRequests      int `json:"last_second_total_requests"`
	TotalDecodeTokens  int `json:"last_second_total_decode_tokens"`
	TotalPrefillTokens int `json:"last_second_total_prefill_tokens"`
	TotalTokens        int `json:"last_second_total_tokens"`
}

func percentile(sortedValues []int64, p int) int64 {
	if len(sortedValues) == 0 {
		return 0
	}

	if len(sortedValues) == 1 {
		return sortedValues[0]
	}

	// Calculate the rank
	rank := float64(p) / 100.0 * float64(len(sortedValues)-1)
	rankInt := int(rank)

	// If rank is an integer, return that value
	if rank == float64(rankInt) {
		return sortedValues[rankInt]
	}

	// Otherwise, interpolate between two values
	fraction := rank - float64(rankInt)
	return int64(float64(sortedValues[rankInt]) + fraction*(float64(sortedValues[rankInt+1])-float64(sortedValues[rankInt])))
}

func (t *PodMetricsTracker) GetDetailedMetrics(log_window_start_time time.Time, numInputTokens int64, numOutputTokens int64, numTotalTokens int64) map[string]PodDetailedMetrics {
	t.mutex.RLock()
	defer t.mutex.RUnlock()
	result := make(map[string]PodDetailedMetrics)
	for podIP, metrics := range t.podMetrics {
		// podMetrics should have all pods in its entry
		// Init here to record all pods even if one does not have metrics after log_window_start_time
		detailedMetrics := PodDetailedMetrics{
			TotalRequests:      -1,
			TotalDecodeTokens:  -1,
			TotalPrefillTokens: -1,
			TotalTokens:        -1,
			TTFTSamples:        -1,
			TPOTSamples:        -1,
			AvgTTFT:            -1,
			MinTTFT:            -1,
			MaxTTFT:            -1,
			P50TTFT:            -1,
			P90TTFT:            -1,
			P95TTFT:            -1,
			P99TTFT:            -1,
			AvgTPOT:            -1,
			MinTPOT:            -1,
			MaxTPOT:            -1,
			P50TPOT:            -1,
			P90TPOT:            -1,
			P95TPOT:            -1,
			P99TPOT:            -1,
		}

		var validMetrics []PodMetric
		for _, m := range metrics {
			if m.Timestamp.After(log_window_start_time) {
				validMetrics = append(validMetrics, m)
			}
		}
		var ttftValues []int64
		var tpotValues []int64
		var ttftSum, tpotSum int64
		var earlyTokensTPOT, midTokensTPOT, lateTokensTPOT []int64
		uniqueRequests := make(map[string]bool)
		totalDecodeTokens := 0
		totalPrefillTokens := 0
		for _, m := range validMetrics {
			if m.TTFT > 0 {
				ttftValues = append(ttftValues, m.TTFT)
				ttftSum += m.TTFT
				uniqueKey := fmt.Sprintf("%s-%d", podIP, m.Timestamp.UnixNano())
				uniqueRequests[uniqueKey] = true
				totalPrefillTokens += int(m.PrefillTokenNum)
			}
			if m.TPOT > 0 {
				tpotValues = append(tpotValues, m.TPOT)
				tpotSum += m.TPOT
				totalDecodeTokens++
				early_token_index := numOutputTokens / 3
				mid_token_index := (numOutputTokens / 3) * 2
				switch {
				case m.DecodeTokenNum <= early_token_index:
					earlyTokensTPOT = append(earlyTokensTPOT, m.TPOT)
				case m.DecodeTokenNum > early_token_index && m.DecodeTokenNum <= mid_token_index:
					midTokensTPOT = append(midTokensTPOT, m.TPOT)
				case m.DecodeTokenNum > mid_token_index:
					lateTokensTPOT = append(lateTokensTPOT, m.TPOT)
				}
			}
		}
		sort.Slice(ttftValues, func(i, j int) bool { return ttftValues[i] < ttftValues[j] })
		sort.Slice(tpotValues, func(i, j int) bool { return tpotValues[i] < tpotValues[j] })

		detailedMetrics.TotalRequests = len(uniqueRequests)
		detailedMetrics.TotalDecodeTokens = totalDecodeTokens
		detailedMetrics.TotalPrefillTokens = totalPrefillTokens
		detailedMetrics.TotalTokens = totalDecodeTokens + totalPrefillTokens
		detailedMetrics.TTFTSamples = len(ttftValues)
		detailedMetrics.TPOTSamples = len(tpotValues)
		if len(ttftValues) > 0 {
			detailedMetrics.AvgTTFT = float64(ttftSum) / float64(len(ttftValues))
			detailedMetrics.MinTTFT = ttftValues[0]
			detailedMetrics.MaxTTFT = ttftValues[len(ttftValues)-1]
			detailedMetrics.P50TTFT = percentile(ttftValues, 50)
			detailedMetrics.P90TTFT = percentile(ttftValues, 90)
			detailedMetrics.P95TTFT = percentile(ttftValues, 95)
			detailedMetrics.P99TTFT = percentile(ttftValues, 99)
		}
		if len(tpotValues) > 0 {
			detailedMetrics.AvgTPOT = float64(tpotSum) / float64(len(tpotValues))
			detailedMetrics.MinTPOT = tpotValues[0]
			detailedMetrics.MaxTPOT = tpotValues[len(tpotValues)-1]
			detailedMetrics.P50TPOT = percentile(tpotValues, 50)
			detailedMetrics.P90TPOT = percentile(tpotValues, 90)
			detailedMetrics.P95TPOT = percentile(tpotValues, 95)
			detailedMetrics.P99TPOT = percentile(tpotValues, 99)
		}

		if len(earlyTokensTPOT) > 0 {
			var sum int64
			for _, v := range earlyTokensTPOT {
				sum += v
			}
			detailedMetrics.EarlyTokensTPOT = float64(sum) / float64(len(earlyTokensTPOT))
		}
		if len(midTokensTPOT) > 0 {
			var sum int64
			for _, v := range midTokensTPOT {
				sum += v
			}
			detailedMetrics.MidTokensTPOT = float64(sum) / float64(len(midTokensTPOT))
		}
		if len(lateTokensTPOT) > 0 {
			var sum int64
			for _, v := range lateTokensTPOT {
				sum += v
			}
			detailedMetrics.LateTokensTPOT = float64(sum) / float64(len(lateTokensTPOT))
		}

		result[podIP] = detailedMetrics
	}
	return result
}

// Helper functions for metrics tracking
// IsMetricsEnabled returns whether metrics collection is enabled
func (s *Server) IsMetricsEnabled() bool {
	return s.metricsEnabled.Load()
}

// EnableMetrics enables metrics collection
func (s *Server) EnableMetrics() {
	s.metricsEnabled.Store(true)
	klog.Info("Metrics collection enabled")
}

// DisableMetrics disables metrics collection
func (s *Server) DisableMetrics() {
	s.metricsEnabled.Store(false)
	klog.Info("Metrics collection disabled")
}
